**Dica: Linguagens para tokenizar (opcional)**

Se quiser mostrar isso de forma prática, pode usar Python com uma função simples como:

```python
def lexer(expr):
    tokens = []
    for part in expr.split():
        if part.isdigit():
            tokens.append(f"[NUM:{part}]")
        else:
            tokens.append(f"[OP:{part}]")
    return tokens

print(lexer("10 + 5 - 2"))
# Saída: ['[NUM:10]', '[OP:+]', '[NUM:5]', '[OP:-]', '[NUM:2]']
```
